---
editor_options: 
title: "assessPOOL: A Variant Annotation Workflow"
output: html_notebook
---

**Copyright E Barba, E Conklin, J Whitney 2018.** 
This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. You should have received a copy of the GNU General Public License along with this program. If not, see http://www.gnu.org/licenses/.

```{r LibraryImport, message=FALSE, warning=FALSE, include=FALSE}
#import necessary R libraries

rm(list=ls())

#auto-installs packrat if not already on machine
if ("packrat" %in% installed.packages == FALSE) install.packages("packrat")

packrat::restore(restart=TRUE) #installs necessary libraries if they are not already included
packrat::on() #initializes packrat library
#Install/upclte Bioconductor
#source("https://bioconductor.org/biocLite.R")
#biocLite()
#library(BiocInstaller)
#biocLite("VariantAnnotation") #to install/upclte packages
#biocLite("GenomicFeatures"); biocLite("ShortRead"); biocLite("Biostrings"); biocLite("Rsamtools")
library(seqinr)
library(stringi) 
library(stringr)
library(R.utils)
#detach("package:VariantAnnotation", unload=TRUE)
library(VariantAnnotation)
library(GenomicFeatures)
library(seqminer)  #library(vcf2geno) replaced by seqminer
library(RJSONIO)
#library(Rplinkseq) #not installed yet
library(reshape2) 
library(dataframes2xls)
library(reshape)
library(dplyr)
library(tidyr)
library(ggplot2)
library(metap)
library(plotly)
library(here)

#import R functions from other scripts
source("scripts/assessPool/assessPool_vcfFilter.R")
source("scripts/assessPool/assessPool_preAnalysis.R")
source("scripts/assessPool/assessPool_syncSetup.R")
source("scripts/assessPool/assessPool_runPopoolation.R")
source("scripts/assessPool/assessPool_postPopoolation.R")
source("scripts/assessPool/assessPool_poolHeatmaps.R")
source("scripts/assessPool/assessPool_visualizations.R")
system("chmod +x scripts/filtering/ErrorCount.sh")

#set working directory
working_dir <- here()

#install vcflib if not already done
vcflib_PATH <- tryCatch({
    system('vcffilter', intern=T, ignore.stderr=T)
    tmp <- ""
  }, error = function(e){ 
    tmp <- paste(working_dir, "scripts", "vcflib", "bin/", sep="/")
    
    if (!file.exists(paste(working_dir, "scripts", "vcflib",sep="/"))){
      setwd(paste(working_dir, "scripts", sep="/"))
      system("git clone --recursive https://github.com/vcflib/vcflib.git")
      system(paste("cd ", paste(working_dir, "scripts", "vcflib/", sep="/"), "; make", sep=""))
      setwd(working_dir)
    } 
    return(tmp)
}, finally = function(e){
  return(tmp)
})

```

Ensure the following files are located in the working directory:

  * \*.vcf        | *FreeBayes produced VCF file*
  * \*.fasta      | *reference fasta (produced by dDocent or from NCBI if mapped directly to reference) *

### Pre-Analysis Setup Parameters
If desired, set project name, paths to input files, and basic filter parameters as described below.  
```{r PreAnalysisParameters}
#set your project name - this will create a directory where output files are stored
#NOTE - it is very important to change this if you are starting a new analysis
#Otherwise it will overwrite your old one 
project_name <- "my_project"

#finds input files (VCF and reference fasta)
#NOTE: if your files are in a different directory, or if you have multiple vcf/ref files,
#replace below with paths to the correct files
vcf_file <- list.files(pattern="*.vcf")[1]
ref_file <- list.files(pattern="*.fasta")[1]

#optional: add your populations/pool labels here if they differ from VCF
#NOTE: it is very important that these names be in the same order as they appear in your VCF file
#uncomment line below to use
#POPS <- c('Pool1', 'Pool2', 'Pool3') 

```

### VCF Filtering Setup (OPTIONAL)
It is strongly recommended that you filter your vcf file before proceeding to reduce sequencing errors and 
improve your signal to noise ratio. If you have filtered your vcf before using assessPool, feel free to skip the
steps below and continue to the PreAnalysisRun notebook chunk. Otherwise, follow the recommended filtering steps
below before proceeding. 

If you wish to start over with your filtering at any time, simply re-run the PreFilteringParameters chunk below.
```{r PreFilteringParameters}
show.filter.output <- TRUE #set to FALSE if you want to suppress verbose output  

filter_df <- vcf_init(vcf_file, working_dir, show.filter.output)
```

### VCF Filtering Steps (OPTIONAL)
The below steps will filter your SNPs into a "filtered_<x>.vcf", which will automatically be used in following steps.
Steps can be re-run with different parameters as needed, but if you are going from a more stringent threshold to a less
stringent one, it will be necessary to start your filtering over by re-running the PreFilteringParameters step first. 
```{r}
#Filter by pool number
min.pool.number <- 2 #minimum number of pools needed for a SNP to be included (DEFAULT=2)
filter_df <- filter_numpools(working_dir, project_name, vcf_file, min.pool.number, filter_df, show.filter.output)
```
```{r}
#Filter by quality score
min.quality.score <- 30 #drops SNPs with quality scores lower than this threshold (DEFAULT=30)
filter_df <- filter_quality(working_dir, project_name, vcf_file, min.quality.score, filter_df, show.filter.output)
```
```{r}
#Filter by minimum depth
min.depth.threshold <- 3 #drops info called in fewer reads (total, not per pool) than this threshold (DEFAULT=3) 
max.missing <- 11 #maximum amount of dropped genotypes due to low coverage for a SNP to be included
#if you want to keep SNPs called in at least one pool, set this number equal to one less than your number of pools
filter_df <- filter_mindepth(working_dir, project_name, vcf_file, min.depth.threshold, max.missing, filter_df, show.filter.output)
```
```{r}
#Filter by allele length
max.allele.length <- 10 #drops SNPs with an allele length greater than this threshold (DEFAULT=10)
filter_df <- filter_maxallelelength(working_dir, project_name, vcf_file, max.allele.length, filter_df, show.filter.output)
```
```{r}
#Filter by mispaired reads
#drops SNPs in which all the reads supporting the reference allele are paired but not supporting the alternate allele
filter_df <- filter_mispaired(working_dir, project_name, vcf_file, filter_df, show.filter.output)
```
```{r}
#Filter by quality : depth ratio
#drops SNPS with a quality score:depth ratio lower than this threshold (DEFAULT=.25)
#this removes low quality, high depth SNPs e.g. loci that were likely overgrouped
quality.depth.ratio <- .25 
filter_df <- filter_qualdepth(working_dir, project_name, vcf_file, quality.depth.ratio, filter_df, show.filter.output)
```
```{r}
#dDocent filtering based on mean depth per site vs. quality score
#helps filter out true variants vs false variants
filter_df <- filter_ddocent(working_dir, project_name, vcf_file, filter_df, show.filter.output)
```
```{r}
#Use the histogram below to help choose a maximum mean depth cutoff - try to reduce trailing tail
#NOTE - histogram generation requires minimum depth filter + ddocent filter to be run previously
depths <- read.table("F5.DEPTH")
ggplot(data=depths) + geom_histogram(aes(x=depths$V1/max.missing), binwidth=10) + xlab("Mean Depth") + ylab("# SNPs") + theme_bw()
```
```{r}
#Filter by maximum mean depth
max.mean.depth.threshold <- 300 #helps remove paralogs and multicopy loci
filter_df <- filter_maxmeandepth(working_dir, project_name, vcf_file, max.mean.depth.threshold, filter_df, show.filter.output)
#try re-running the histogram above to see changes
```

### Filtering visualization (OPTIONAL)
Summary of # SNPs retained after each individual filtering step.
```{r}
#Number of SNPs kept after each filter applied
filter_df$Filter_f <- factor(filter_df$Filter, levels=unique(filter_df$Filter))
filter_df$SNPs_f <- as.numeric(as.character(filter_df$SNPs)); options(scipen = 999)
ggplot(data=filter_df) + geom_bar(aes(x=Filter_f, y=SNPs_f), stat="identity") + theme_bw() + theme(axis.text.x = element_text(angle = -70, hjust=-0.1), plot.title = element_text(hjust = 0.5)) + ggtitle("Number of SNPs after each filter") + xlab("\nFilter") + ylab("\n# SNPs")
filter_df$Filter_f <- NULL; filter_df$SNPs_f <- NULL
```

### Run Pre-Analysis Setup
Takes parameters above and runs the script *preAnalysis.R*. This script reads the provided VCF and FASTA files, translates them into R-friendly dataframes, and performs basic filtering based on minimum pool number, minimum total coverage per variable site, and maximum insertion/deletion length. Returns:  

  * dataframe **"master_df"**   | *filtered dataframe, one row per variable site, with pool-specific measures*
  * dataframe **"stacked_df"**  | *filtered dataframe in long format, one row per pool comparison per variable site* 
  * list **"POPS"**             | *list of all pool names*
  * matrix **"popcomb"**        | *matrix of all possible pool comparisons*

```{r PreAnalysisRun, warning=TRUE}

#runs pre-analysis
pa_list_out <- preAnalysis(working_dir=working_dir, 
                               project_name=project_name, 
                               POPS=NULL, min.pool.number=min.pool.number, 
                               min.depth.threshold=min.depth.threshold, 
                               max.indel.length=max.indel.length, 
                               include.multiallelic=include.multiallelic, 
                               include.indels=include.indels, 
                               vcf_file=vcf_file, 
                               ref_file=ref_file)
    
#returns master dataframe and stacked dataframe
as <- pa_list_out$as 
as.st <- pa_list_out$as.st 
POPS <- pa_list_out$POPS 
popcomb <- pa_list_out$popcomb #rename to poolcomb
project_name <- pa_list_out$project_name

```

### PoPoolation2 Parameters
Set parameters for data inclusion, analysis inclusion, and PoPoolation2 run as described below.  

  * It is important that pool size is set, either for actual pool size or effective pool size (e.g. Gautier et al. 2013)
```{r PopoolationParameters}
#options for data inclusion - if both are FALSE, only biallelic SNPs will be included in SYNC files
include.multiallelic <- TRUE
include.indels <- TRUE

#choose which analyses you would like to perform
perform_snpfreq <- FALSE #SNP frequency
perform_fst <- TRUE #Fixation index
perform_fet <- TRUE #Fisher's exact test

#PoPoolation2 Parameters (SNP frequency, FST, FET)

#add T/F option for site-by-site vs sliding

#the minimum count of the minor allele. used for SNP identification.
#SNPs will be identified considering all populations simultanously (DEFAULT=2)
min_count <- 2

#the minimum coverage; used for SNP identification, the coverage in
#ALL populations has to be higher or equal to this threshold, otherwise no SNP will be called. (DEFAULT=4)
min_cov <- 3

#The maximum coverage; All populations are required to have coverages
#lower or equal than the maximum coverage; Mandatory The maximum coverage may be provided as one of the following:
#         '500' a maximum coverage of 500 will be used for all populations
#         '300,400,500' a maximum coverage of 300 will be used for the first population, a maximum coverage of 400 for the second population and so on
#         '2%' the 2% highest coverages will be ignored, this value is independently estimated for every population
#(DEFAULT=1000)
max_cov <- 1000

#the minimum fraction of a window being between min-coverage and
#max-coverage in ALL populations; (DEFAULT=1)
min_covered_fract <- 1

#the size of the sliding window. Measured in "--window-unit"; (DEFAULT=1)
window_size <- 1

#the size of the sliding window steps. Measured in "--window-unit"; (DEFAULT=1)
step_size <- 1

#the size of the population pools; May be provided for each
#population individually; mandatory parameter
#         --pool-size 500 .. all populations have a pool size of 500
#         --pool-size 500:300:600 .. first population has a pool size of 500, the seccond of 300 etc;
#           the number of pools has to fit with the number of populations provided in the file
pool_size <- 50

```

### Run PoPoolation2 Script Setup
Takes parameters above and generates PoPoolation2 run script ("popoolation/popool2_run.sh"), pairwise .sync files needed for PoPoolation2 (in "popoolation/"), and summary files (in "output/"):

  * All variable sites, tab-separated
  * All SNPs, tab-separated
  * All bi-allelic SNPs, tab-separated
  * All 1-base insertions/deletions, tab-separated (note - insertions are coded as deletions to work with PoPoolation2)
```{r PopoolationSetupRun, warning=FALSE}
syncSetup(project_name=project_name,
          as.st=as.st, 
          POPS=POPS, 
          popcomb=popcomb, 
          include.multiallelic=include.multiallelic, 
          include.indels=include.indels, 
          perform_snpfreq=perform_snpfreq, 
          perform_fst=perform_fst, 
          perform_fet=perform_fet, 
          min_count=min_count, 
          min_cov=min_cov, 
          max_cov=max_cov, 
          min_covered_fract=min_covered_fract, 
          window_size=window_size, 
          step_size=step_size, 
          pool_size=pool_size)

```

### Run PoPoolation2 
Runs PoPoolation2 to generate FST/FET values, using the .sync files and run script generated above. Note - this step may take a while! Will generate output files in "popoolation/" for each comparison for each analysis specified.
```{r PopoolationRun, warning=FALSE}

#parallel options
use_parallel <- FALSE #set to FALSE if not using GNU parallel
no_cores <- 20 #number of cores to use for analysis (try not to use max)

runPopoolation(use_parallel=use_parallel, 
               no_cores=no_cores, 
               working_dir=working_dir, 
               project_name=project_name)

```

### PoolSeq Analysis Parameters
Set parameters for post-PoPoolation analysis: FST cutoff, p-value cutoff, and desired range of coverage levels for summary analysis.
```{r AnalysisParameters}
#an FST value between 0 and 1 considered strong differentiation
#NOTE - will only affect output files, not calculations (DEFAULT=0.5)
strong_diff <- 0.5

#a p-value cutoff for Fisher's Exact Test between 0 and 1 
#NOTE - will only affect output files, not calculations (DEFAULT=0.01)
p_cutoff <- 0.01

#if set to true, will pull contig sequences and create FASTA files for
#strongly differentiated and alternatively fixed sites. 
fasta_generation <- TRUE

#minimum coverage levels to use for analysis series
#coverage will go from the min to the max by the step, e.g.
#first_mincov=5, last_mincov=75, cov_step=5 will produce analyses for 5x, 10x, 15x...70x, 75x
first_mincov=5
last_mincov=75
cov_step=5

```

### Summarize PoolSeq Analysis 
Provides summary of sequence metrics over provided range of coverage levels; requires previous .fst/.fet file generation from PoPoolation2. Returns following dataframes for later visualization purposes:

  * **"cov.allpairs.table.total"**    | *summary statistics for all variable sites, across pools*
  * **"cov.allpairs.table.allpools"** | *summary statistics for sites called in all pools, across pools*
  * **"cov.perpair.table.total"**     | *summary statistics for all variable sites, by pairwise comparison*
  * **"cov.perpair.table.allpools"**  | *summary statistics for sites called in all pools, by pairwise comparison*
  * **"postpop.master.long"**         | *all variable sites after PoPoolation2, one row per comparison per site*
  * **"postpop.master.long.allpools"**| *all variable sites after PoPoolation2 that are called in all pools, one row per comparison per site*
  
Outputs following summary files in "output/":

  * All informative variable sites after PoPoolation2, comma-separated
  * All variable sites called in all pools, comma-separated 
  * Strongly differentiated (high FST) sites, comma-separated
  * Alternatively fixed (FST=1) sites, comma-separated
  * Low P-value sites, comma-separated

```{r AnalysisRun, warning=FALSE}
setwd(paste(working_dir, project_name, "popoolation", sep="/"))

if (length(list.files(pattern=".fst"))==0 & length(list.files(pattern=".fet"))==0){
  message("\n\nERROR: No .fst/.fet PoPoolation2 output files found. Please run PoPoolation2.")
} else {
  if (length(list.files(pattern=".fst"))>0 & length(list.files(pattern=".fet"))>0){ filetype = c(".fst",".fet")
  }else if(length(list.files(pattern=".fst"))>0 & length(list.files(pattern=".fet"))==0){ filetype = c(".fst")
  }else if (length(list.files(pattern=".fst"))==0 & length(list.files(pattern=".fet"))>0){ filetype = c(".fet")}
  
  pa_list_out <- postPopoolation(filetype=filetype,
                  project_name=project_name,
                  as=as, 
                  popcomb=popcomb, 
                  strong_diff=strong_diff,
                  p_cutoff=p_cutoff,
                  fasta_generation=fasta_generation,
                  ref_file=ref_file,
                  first_mincov=first_mincov,
                  last_mincov=last_mincov,
                  cov_step=cov_step)
  
  #extract needed data from return values
  cov.allpairs.table.total <- pa_list_out$cov.allpairs.table.total
  cov.perpair.table.total <- pa_list_out$cov.perpair.table.total
  cov.allpairs.table.allpools <- pa_list_out$cov.allpairs.table.allpools
  cov.perpair.table.allpools <- pa_list_out$cov.perpair.table.allpools
  postpop.master.long <- pa_list_out$postpop.master.long
  postpop.master.long.allpools <- pa_list_out$postpop.master.long.allpools
    
}

```

### Summary Visualization By Coverage, sites called in all sites and in all pools
Number of SNPs, Number of Contigs, Mean # SNPs per contigs, Mean FST, SD FST for all sites (total) and all sites
```{r SummaryAllPools, Summary AllSites}
allpairs_summary_plot(cov.allpairs.table.total = cov.allpairs.table.total, cov.allpairs.table.allpools = cov.allpairs.table.allpools)
```

### Summary visualization by coverage and comparison, all sites
```{r PairwiseSummaryAllSites}
ggplotly(ggplot(cov.perpair.table.total, aes(x=MeanFST, y=pair, colour=NumSNPs)) + geom_point() + theme_bw() + xlab("Mean FST") + ylab("Pair") + ggtitle("Mean FST by comparison + # SNPs") + theme(plot.title = element_text(hjust = 0.5)))
ggplotly(ggplot(cov.perpair.table.total, aes(x=MeanFST, y=pair, colour=MinCoverage)) + geom_point() + theme_bw() + xlab("Mean FST") + ylab("Pair") + ggtitle("Mean FST by comparison + coverage") + theme(plot.title = element_text(hjust = 0.5)))
ggplotly(ggplot(cov.perpair.table.total, aes(x=MinCoverage, y=MeanFST, colour=NumSNPs)) + geom_point() + theme_bw() + xlab("Coverage") + ylab("Mean FST") + ggtitle("Mean FST by coverage + # SNPs") + theme(plot.title = element_text(hjust = 0.5)))
ggplotly(ggplot(cov.perpair.table.total, aes(x=MinCoverage, y=MeanFST, colour=pair)) + geom_point() + geom_line() + theme_bw() + xlab("Coverage") + ylab("Mean FST") + ggtitle("Mean FST by coverage + comparison") + theme(plot.title = element_text(hjust = 0.5)))
ggplotly(ggplot(cov.perpair.table.total, aes(x=MinCoverage, y=log(NumSNPs), colour=pair)) + geom_point() + geom_line() + theme_bw() + xlab("Coverage") + ylab("Log # SNPs") + ggtitle("# SNPs by coverage + comparison") + theme(plot.title = element_text(hjust = 0.5)))
```


### Summary visualization by coverage and comparison, sites called in all pools
```{r PairwiseSummaryAllPools}
ggplotly(ggplot(cov.perpair.table.allpools, aes(x=MeanFST, y=pair, colour=NumSNPs)) + geom_point() + theme_bw() + xlab("Mean FST") + ylab("Pair") + ggtitle("Mean FST by comparison + # SNPs") + theme(plot.title = element_text(hjust = 0.5)))
ggplotly(ggplot(cov.perpair.table.allpools, aes(x=MeanFST, y=pair, colour=MinCoverage)) + geom_point() + theme_bw() + xlab("Mean FST") + ylab("Pair") + ggtitle("Mean FST by comparison + coverage") + theme(plot.title = element_text(hjust = 0.5)))
ggplotly(ggplot(cov.perpair.table.allpools, aes(x=MinCoverage, y=MeanFST, colour=NumSNPs)) + geom_point() + theme_bw() + xlab("Coverage") + ylab("Mean FST") + ggtitle("Mean FST by coverage + # SNPs") + theme(plot.title = element_text(hjust = 0.5)))
ggplotly(ggplot(cov.perpair.table.allpools, aes(x=MinCoverage, y=MeanFST, colour=pair)) + geom_point() + geom_line() + theme_bw() + xlab("Coverage") + ylab("Mean FST") + ggtitle("Mean FST by coverage + comparison") + theme(plot.title = element_text(hjust = 0.5)))
```

### FST heatmap parameters
Choose a coverage cutoff and whether to only include sites called in all pools for heatmap generation.
```{r FSTHeatmaps}
#pick a heatmap coverage based on summary plots above
heatmap_cov <- 5

#include only SNPs called in all pools?
all_pools <- FALSE

if (all_pools){ postpop <- postpop.master.long.allpools
} else{ postpop <- postpop.master.long }

hm_list_out <- poolHeatmaps(heatmap_cov=heatmap_cov, postpop=postpop)
fst <- as.matrix(hm_list_out$fst)
chisq <- as.matrix(hm_list_out$chisq)
```

### Drawing heatmaps
```{r DrawHeatmaps}
#plot heatmaps
plot_ly(z = fst, colors = colorRamp(c("yellow", "red")), x = colnames(fst), y=rownames(fst), type = "heatmap",
        colorbar = list(title = "FST"))
plot_ly(z = chisq, colors = colorRamp(c("yellow", "red")), x = colnames(chisq), y=rownames(chisq), type = "heatmap",
        colorbar = list(title = "Chi-Squared"))

# cluster FST rows, transpose the matrix and cluster columns
hc.rows <- hclust(dist(fst))
hc.cols <- hclust(dist(t(fst)))

heatmap(fst)

# draw heatmap for first cluster
#heatmap(fst[cutree(hc.rows,k=3)==1,], Colv=as.dendrogram(hc.cols), scale='none')
# draw heatmap for second cluster
#heatmap(fst[cutree(hc.rows,k=3)==2,], Colv=as.dendrogram(hc.cols), scale='none')

```
