---
editor_options: 
title: "assessPOOL: A Variant Annotation Workflow"
output: html_notebook
---

**Copyright E Barba, E Conklin, J Whitney 2018.** 
This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. You should have received a copy of the GNU General Public License along with this program. If not, see http://www.gnu.org/licenses/.

```{r LibraryImport, message=FALSE, warning=FALSE, include=FALSE}
#import necessary R libraries

rm(list=ls())
#lapply(paste('package:',names(sessionInfo()$otherPkgs),sep=""),detach,character.only=TRUE,unload=TRUE)

#auto-installs packrat if not already on machine
if ("packrat" %in% installed.packages() == FALSE) install.packages("packrat")

packrat::restore(restart=TRUE) #installs necessary libraries if they are not already included
packrat::on() #initializes packrat library
#Install/upclte Bioconductor
#source("https://bioconductor.org/biocLite.R")
#biocLite()
#library(BiocInstaller)
#biocLite("VariantAnnotation") #to install/upclte packages
#biocLite("GenomicFeatures"); biocLite("ShortRead"); biocLite("Biostrings"); biocLite("Rsamtools")
#attachNamespace('stringi')
library(stringi)
library(seqinr)
library(stringr)
library(R.utils)
#detach("package:VariantAnnotation", unload=TRUE)
library(VariantAnnotation)
library(GenomicFeatures)
library(seqminer)  #library(vcf2geno) replaced by seqminer
library(RJSONIO)
#library(Rplinkseq) #not installed yet
library(reshape2) 
library(dataframes2xls)
library(reshape)
library(dplyr)
library(tidyr)
library(ggplot2)
library(metap)
library(plotly)
library(here)
library(poolfstat)
library(ggrepel)
library(maps)

#import R functions from other scripts
source("scripts/assessPool/assessPool_vcfFilter.R")
source("scripts/assessPool/assessPool_preAnalysis.R")
source("scripts/assessPool/assessPool_syncSetup.R")
#source("scripts/assessPool/assessPool_runPopoolation.R")
source("scripts/assessPool/assessPool_calculateFST.R")
#source("scripts/assessPool/assessPool_postPopoolation.R")
source("scripts/assessPool/assessPool_postFST.R")
source("scripts/assessPool/assessPool_poolHeatmaps.R")
source("scripts/assessPool/assessPool_visualizations.R")
system("chmod +x scripts/filtering/ErrorCount.sh")

#set working directory
working_dir <- here()

#install vcflib if not already done
vcflib_PATH <- tryCatch({
    system('vcffilter', intern=T, ignore.stderr=T)
    tmp <- ""
  }, error = function(e){ 
    tmp <- paste(working_dir, "scripts", "vcflib", "bin/", sep="/")
    
    if (!file.exists(paste(working_dir, "scripts", "vcflib",sep="/"))){
      setwd(paste(working_dir, "scripts", sep="/"))
      system("git clone --recursive https://github.com/vcflib/vcflib.git")
      system(paste("cd ", paste(working_dir, "scripts", "vcflib/", sep="/"), "; make", sep=""))
      setwd(working_dir)
    } 
    return(tmp)
}, finally = function(e){
  return(tmp)
})

project_name <- NULL
vcf_starting_file <- NULL
ref_file <- NULL

```

Ensure the following files are located in the working directory:

  * \*.vcf        | *FreeBayes produced VCF file*
  * \*.fasta      | *reference fasta (produced by dDocent or from NCBI if mapped directly to reference) *

### Pre-Analysis Setup Parameters
If desired, set project name, paths to input files, and basic filter parameters as described below.  
```{r PreAnalysisParameters}
#set your project name - this will create a directory where output files are stored
#NOTE - it is very important to change this if you are starting a new analysis
#Otherwise it will overwrite your old one 


if(any(exists("project_name")==F | is.null(project_name) |
       exists("vcf_file")==F | is.null(vcf_file) |
       exists("ref_file")==F) | is.null(ref_file)){
 if(showQuestion(title="Change files?", 
                 message=paste("Project name:", project_name, "***** VCF: ", vcf_file, "***** Reference: ", ref_file), 
                 ok = "Yes, change", 
                 cancel = "No, accept input")==T) {
   
project_name <- showPrompt(title="Project Name?", message = paste("Choose your name for this project (current name:", project_name, ")"))
}
#prompt for input files (VCF and reference fasta)

vcf_starting_file <- basename(selectFile(caption = "Select VCF File", label = "Select",
path = getActiveProject(), filter = "VCF Files (*.vcf)", existing = T))

#vcf_file <- basename(
  
ref_file <- basename(selectFile(caption = "Select Reference fasta", label = "Select",
path = getActiveProject(), filter = "Reference Files (*.fasta) | (*.fa)",
existing = T))
} else {
  project_name <- project_name
vcf_starting_file <- vcf_starting_file
ref_file <- ref_file
}
  
showDialog(title = "Confirm?",
           message = paste("<b>Project name:</b> <i>", project_name, "</i>",
                            "<b>VCF</b>: <i>", vcf_file, "</i>",
                            "<b>Reference:</b> <i>", ref_file, "</i>") )
                           

#optional: add your populations/pool labels here if they differ from VCF
#NOTE: it is very important that these names be in the same order as they appear in your VCF file
#uncomment line below to use
#POPS <- c('Pool1', 'Pool2', 'Pool3') 

pool_num <- length(samples(scanVcfHeader(vcf_starting_file)))
```

### VCF Filtering Setup (OPTIONAL)
It is strongly recommended that you filter your vcf file before proceeding to reduce sequencing errors and 
improve your signal to noise ratio. If you have filtered your vcf before using assessPool, feel free to skip the
steps below and continue to the PreAnalysisRun notebook chunk. Otherwise, follow the recommended filtering steps
below before proceeding. 

If you wish to start over with your filtering at any time, simply re-run the PreFilteringParameters chunk below.
```{r PreFilteringParameters}
show.filter.output <- TRUE #set to FALSE if you want to suppress verbose output  

filter_df <- vcf_init(vcf_starting_file, working_dir, show.filter.output)
```

### VCF Filtering Steps (OPTIONAL)
The below steps will filter your SNPs into a "filtered_<x>.vcf", which will automatically be used in following steps.
Steps can be re-run with different parameters as needed, but if you are going from a more stringent threshold to a less
stringent one, it will be necessary to start your filtering over by re-running the PreFilteringParameters step first. 
```{r}
#Filter by pool number
min.pool.number <- 2 #minimum number of pools needed for a SNP to be included (DEFAULT=2)
filter_df <- filter_numpools(working_dir, project_name, vcf_file, min.pool.number, filter_df, show.filter.output)
```
```{r}
#Filter by indel and multiallelic SNPs
keep.indel <- FALSE
keep.multiallelic <- TRUE
#filter_df <- filter_indels(working_dir, project_name, vcf_file, keep.indel, keep.multiallelic, filter_df, show.filter.output)
```

```{r}
#Filter by quality score
min.quality.score <- 30 #drops SNPs with quality scores lower than this threshold (DEFAULT=30)
filter_df <- filter_quality(working_dir, project_name, vcf_file, min.quality.score, filter_df, show.filter.output)
```

```{r}
#Filter by minimum depth
min.depth.threshold <- 3 #drops info called in fewer reads (total, not per pool) than this threshold (DEFAULT=3) 
max.missing <- pool_num-1 #maximum amount of dropped genotypes due to low coverage for a SNP to be included
#if you want to keep SNPs called in at least one pool, set this number equal to one less than your number of pools
filter_df <- filter_mindepth(working_dir, project_name, vcf_file, min.depth.threshold, max.missing, filter_df, show.filter.output)
```

```{r}
#Filter by allele length
max.allele.length <- 10 #drops SNPs with an allele length greater than this threshold (DEFAULT=10)
filter_df <- filter_maxallelelength(working_dir, project_name, vcf_file, max.allele.length, filter_df, show.filter.output)
```

```{r}
#Filter by mispaired reads
#drops SNPs in which all the reads supporting the reference allele are paired but not supporting the alternate allele
filter_df <- filter_mispaired(working_dir, project_name, vcf_file, filter_df, show.filter.output)
```

```{r}
#Filter by quality : depth ratio
#drops SNPS with a quality score:depth ratio lower than this threshold (DEFAULT=.25)
#this removes low quality, high depth SNPs e.g. loci that were likely overgrouped
quality.depth.ratio <- .25 
filter_df <- filter_qualdepth(working_dir, project_name, vcf_file, quality.depth.ratio, filter_df, show.filter.output)
```

```{r}
#dDocent filtering based on mean depth per site vs. quality score
#helps filter out true variants vs false variants
filter_df <- filter_ddocent(working_dir, project_name, vcf_file, filter_df, show.filter.output)
```

```{r}
#Use the histogram below to help choose a maximum mean depth cutoff - try to reduce trailing tail
#NOTE - histogram generation requires minimum depth filter + ddocent filter to be run previously
depths <- read.table("F5.DEPTH")
ggplotly(ggplot(data=depths) + geom_histogram(aes(x=depths$V1/max.missing), binwidth=10) + xlab("Mean Depth") + ylab("# SNPs") + theme_bw())
```

```{r}
#Filter by maximum mean depth
max.mean.depth.threshold <- 500 #helps remove paralogs and multicopy loci
filter_df <- filter_maxmeandepth(working_dir, project_name, vcf_file, max.mean.depth.threshold, filter_df, show.filter.output)
#try re-running the histogram above to see changes
```

### Filtering visualization (OPTIONAL)
Summary of # SNPs retained after each individual filtering step.
```{r}
#Number of SNPs kept after each filter applied
filter_df$Filter_f <- factor(filter_df$Filter, levels=unique(filter_df$Filter))
filter_df$SNPs_f <- as.numeric(as.character(filter_df$SNPs)); options(scipen = 999)
ggplotly(ggplot(data=filter_df) + geom_bar(aes(x=Filter_f, y=SNPs_f), stat="identity") + theme_bw() + theme(axis.text.x = element_text(angle = -70, hjust=-0.1), plot.title = element_text(hjust = 0.5)) + ggtitle("Number of SNPs after each filter") + xlab("\nFilter") + ylab("\n# SNPs"))
filter_df$Filter_f <- NULL; filter_df$SNPs_f <- NULL
```

### Run Pre-Analysis Setup
Takes parameters above and runs the script *preAnalysis.R*. This script reads the provided VCF and FASTA files and translates them into R-friendly dataframes.

  * dataframe **"master_df"**   | *filtered dataframe, one row per variable site, with pool-specific measures*
  * dataframe **"stacked_df"**  | *filtered dataframe in long format, one row per pool comparison per variable site* 
  * list **"POPS"**             | *list of all pool names*
  * matrix **"popcomb"**        | *matrix of all possible pool comparisons*
  
**NOTE - depending on number of pools and SNPs, this step may take a while!**
  
```{r PreAnalysisRun, warning=TRUE}

#runs pre-analysis
pa_list_out <- preAnalysis(working_dir=working_dir, 
                               project_name=project_name, 
                               POPS=NULL, 
                               vcf_file=vcf_file, 
                               ref_file=ref_file)
    
#returns master dataframe and stacked dataframe
as <- pa_list_out$as 
as.st <- pa_list_out$as.st 
POPS <- pa_list_out$POPS 
popcomb <- pa_list_out$popcomb 
project_name <- pa_list_out$project_name

```

### Set parameters for Fst Calculation
```{r Fst Parameters}

## Fst calculation
#Specify which software to use for Fst calculation, either the library 'poolfstat' or the standalone software 'PoPoolation2'.
#For both, use c("poolfstat", "popoolation")
#Poolfstat is default and recommended - see Hivert et al 2018 for more details.
fst.calc <- c("poolfstat", "popoolation")

# Additional filtering parameters - pool size MUST be specified
include.multiallelic <- TRUE #whether to include multiallelic sites in analysis
include.indels <- FALSE #whether to include insertions and deletions in analysis
min_count <- 2 #minimum count of minor allele (DEFAULT=2)
min_cov <- 2 #minimum coverage (in ALL populations) (DEFAULT=2)
max_cov <- 1000 #maximum coverage, provide either a single value or a vector of maximum values per population (DEFAULT=1000)
#vector example for three populations:
#max_cov <- c(500, 600, 700)
window_size <- 1 #set to 1 for SNP-specific FST calculation
pool_size <- c(40,40)
 #number of individuals per pool, provide either a single value or a vector of individuals per pool
#vector example for three populations:
#pool_size <- c(53, 57, 46)
#(DEFAULT=2 for pairwise comparisons)

#parallel options
use_parallel <- TRUE #set to FALSE if not using GNU parallel
no_cores <- 20 #number of cores to use for analysis (try not to use max)

#sudo options for perl module
use_sudo <- T #use sudo permissions to install "Text::NSP::Measures::2D::Fisher::twotailed" perl module for popoolation2

```

### Calculate Pairwise Fst
Takes parameters above and generates pairwise .sync files (in "sync/"), PoPoolation2 run script if using this software ("popoolation/popool2_run.sh"), and summary files (in "output/"):
  *All variable sites, tab-separated*
  *All SNPs, tab-separated*
  *All bi-allelic SNPs, tab-separated*
  *All 1-base insertions/deletions, tab-separated (note - insertions are coded as deletions to work with Fst calc)*

Will also generate FST output files in "popoolation/" and/or "poolfstat/"

```{r}

calculateFST(use_parallel=use_parallel, 
             no_cores=no_cores, 
             working_dir=working_dir, 
             project_name=project_name,
             fst.calc=fst.calc,
             as.st=as.st, 
             POPS=POPS, 
             popcomb=popcomb, 
             include.multiallelic=include.multiallelic, 
             include.indels=include.indels, 
             min_count=min_count, 
             min_cov=min_cov, 
             max_cov=max_cov, 
             pool_size=pool_size,
             use_sudo=use_sudo)

```

### PoolSeq Analysis Parameters
Set parameters for post-PoPoolation analysis: FST cutoff, p-value cutoff, and desired range of coverage levels for summary analysis.
```{r AnalysisParameters}
#an FST value between 0 and 1 considered strong differentiation
#NOTE - will only affect output files, not calculations (DEFAULT=0.5)
strong_diff <- 0.5

#a p-value cutoff for Fisher's Exact Test between 0 and 1 
#NOTE - will only affect output files, not calculations (DEFAULT=0.01)
p_cutoff <- 0.01

#if set to true, will pull contig sequences and create FASTA files for
#strongly differentiated and alternatively fixed sites. 
fasta_generation <- TRUE

#minimum coverage levels to use for analysis series
#coverage will go from the min to the max by the step, e.g.
#first_mincov=5, last_mincov=75, cov_step=5 will produce analyses for 5x, 10x, 15x...70x, 75x
first_mincov=5
last_mincov=75
cov_step=5
```

### Summarize PoolSeq Analysis 
Provides summary of sequence metrics over provided range of coverage levels; requires previous .fst/.fet file generation from PoPoolation2. Returns following dataframes for later visualization purposes:

  * **"cov.allpairs.table.total"**    | *summary statistics for all variable sites, across pools*
  * **"cov.allpairs.table.allpools"** | *summary statistics for sites called in all pools, across pools*
  * **"cov.perpair.table.total"**     | *summary statistics for all variable sites, by pairwise comparison*
  * **"cov.perpair.table.allpools"**  | *summary statistics for sites called in all pools, by pairwise comparison*
  * **"postpop.master.long"**         | *all variable sites after PoPoolation2, one row per comparison per site*
  * **"postpop.master.long.allpools"**| *all variable sites after PoPoolation2 that are called in all pools, one row per comparison per site*
  
Outputs following summary files in "output/":

  * All informative variable sites after PoPoolation2, comma-separated
  * All variable sites called in all pools, comma-separated 
  * Strongly differentiated (high FST) sites, comma-separated
  * Alternatively fixed (FST=1) sites, comma-separated
  * Low P-value sites, comma-separated

```{r AnalysisRun, warning=FALSE}

if("popoolation" %in% fst.calc){
  setwd(paste(working_dir, project_name, "popoolation", sep="/"))
  
  if (length(list.files(pattern=".fst"))==0 & length(list.files(pattern=".fet"))==0){
    message("\n\nERROR: No .fst/.fet PoPoolation2 output files found. Please run PoPoolation2.")
  } else {
    if (length(list.files(pattern=".fst"))>0 & length(list.files(pattern=".fet"))>0){ filetype = c(".fst",".fet")
    }else if(length(list.files(pattern=".fst"))>0 & length(list.files(pattern=".fet"))==0){ filetype = c(".fst")
    }else if (length(list.files(pattern=".fst"))==0 & length(list.files(pattern=".fet"))>0){ filetype = c(".fet")}
    
    pa_list_out <- postFST(fst.calc="popoolation",
                           filetype=filetype,
                           project_name=project_name,
                           as=as, 
                           popcomb=popcomb, 
                           strong_diff=strong_diff,
                           p_cutoff=p_cutoff,
                           fasta_generation=fasta_generation,
                           ref_file=ref_file,
                           first_mincov=first_mincov,
                           last_mincov=last_mincov,
                           cov_step=cov_step)
    
    #extract needed data from return values
    cov.allpairs.table.total_popoolation <- pa_list_out$cov.allpairs.table.total
    cov.perpair.table.total_popoolation <- pa_list_out$cov.perpair.table.total
    cov.allpairs.table.allpools_popoolation <- pa_list_out$cov.allpairs.table.allpools
    cov.perpair.table.allpools_popoolation <- pa_list_out$cov.perpair.table.allpools
    postpop.master.long_popoolation <- pa_list_out$postpop.master.long
    postpop.master.long.allpools_popoolation <- pa_list_out$postpop.master.long.allpools
      
  }
}

if("poolfstat" %in% fst.calc){
setwd(paste(working_dir, project_name, "poolfstat", sep="/"))

if (length(list.files(pattern=".fst"))==0){
  message("\n\nERROR: No .fst/.fet PoPoolation2 output files found. Please run PoPoolation2.")
} else {
  filetype = c(".fst")}
  
  pa_list_out <- postFST(fst.calc="poolfstat",
                           filetype=filetype,
                           project_name=project_name,
                           as=as, 
                           popcomb=popcomb, 
                           strong_diff=strong_diff,
                           p_cutoff=p_cutoff,
                           fasta_generation=fasta_generation,
                           ref_file=ref_file,
                           first_mincov=first_mincov,
                           last_mincov=last_mincov,
                           cov_step=cov_step)
  
  #extract needed data from return values
  cov.allpairs.table.total_poolfstat <- pa_list_out$cov.allpairs.table.total
  cov.perpair.table.total_poolfstat <- pa_list_out$cov.perpair.table.total
  cov.allpairs.table.allpools_poolfstat <- pa_list_out$cov.allpairs.table.allpools
  cov.perpair.table.allpools_poolfstat <- pa_list_out$cov.perpair.table.allpools
  postpop.master.long_poolfstat <- pa_list_out$postpop.master.long
  postpop.master.long.allpools_poolfstat <- pa_list_out$postpop.master.long.allpools
    
}

```

### Summary Visualization By Coverage, sites called in all sites and in all pools
Number of SNPs, Number of Contigs, Mean # SNPs per contigs, Mean FST, SD FST for all sites (total) and all sites
```{r SummaryAllPools, Summary AllSites}
if("popoolation" %in% fst.calc){
    allpairs_summary_plot(cov.allpairs.table.total = cov.allpairs.table.total_popoolation, cov.allpairs.table.allpools = cov.allpairs.table.allpools_popoolation)
}
if("poolfstat" %in% fst.calc){
    allpairs_summary_plot(cov.allpairs.table.total = cov.allpairs.table.total_poolfstat, cov.allpairs.table.allpools = cov.allpairs.table.allpools_poolfstat)
}
```


### Wrangling for figures
```{r}
if("popoolation" %in% fst.calc){
    postpop.master.wide_pp <- spread(postpop.master.long_popoolation, analysis, value)
    postpop.master.wide_pp$pair <- gsub(paste0(project_name,"_"), "", postpop.master.wide_pp$pair) 
    postpop.master.wide_pp <- separate(postpop.master.wide_pp, pair, c("popA","popB"), sep="_", remove=F)

    cov.perpair.table.total_pp <- cov.perpair.table.total_popoolation[order(cov.perpair.table.total_popoolation$MinCoverage),]
    cov.perpair.table.total_pp <- separate(cov.perpair.table.total_pp, pair, c("popA","popB"), sep="_", remove=F)
    cov.perpair.table.total_pp$NumSNPs <- as.numeric(cov.perpair.table.total_pp$NumSNPs)
    cov.perpair.table.total_pp$NumContigs <- as.numeric(cov.perpair.table.total_pp$NumContigs)
    cov.perpair.table.total_pp$pair <- as.character(cov.perpair.table.total_pp$pair)
}

if("poolfstat" %in% fst.calc){
    postpop.master.wide_pf <- spread(postpop.master.long_poolfstat, analysis, value)
    postpop.master.wide_pf$pair <- gsub(paste0(project_name,"_"), "", postpop.master.wide_pf$pair) 
    postpop.master.wide_pf <- separate(postpop.master.wide_pf, pair, c("popA","popB"), sep="_", remove=F)

    cov.perpair.table.total_pf <- cov.perpair.table.total_poolfstat[order(cov.perpair.table.total_poolfstat$MinCoverage),]
    cov.perpair.table.total_pf <- separate(cov.perpair.table.total_pf, pair, c("popA","popB"), sep="_", remove=F)
    cov.perpair.table.total_pf$NumSNPs <- as.numeric(cov.perpair.table.total_pf$NumSNPs)
    cov.perpair.table.total_pf$NumContigs <- as.numeric(cov.perpair.table.total_pf$NumContigs)
    cov.perpair.table.total_pf$pair <- as.character(cov.perpair.table.total_pf$pair)
}
```

```{r}
if("popoolation" %in% fst.calc){
 cov.perpair.table.total_pp %>%
  plot_ly(
    x = ~MeanFST, 
    y = ~pair, 
    color = ~NumSNPs,
    frame = ~MinCoverage, 
    text = ~NumContigs, 
    hoverinfo = ~pair,
    type = 'scatter',
    mode = 'markers',
    marker = list(size = 12)
  ) %>%
  layout(margin=list(l = 100, r = 20, b = 10, t = 10)) %>%
  layout(yaxis = list(tickangle=-35,tickfont=list(size=12))) %>%
  layout(xaxis = list(tickfont=list(size=12)))
}

if("poolfstat" %in% fst.calc){
 cov.perpair.table.total_pf %>%
  plot_ly(
    x = ~MeanFST, 
    y = ~pair, 
    color = ~NumSNPs,
    frame = ~MinCoverage, 
    text = ~NumContigs, 
    hoverinfo = ~pair,
    type = 'scatter',
    mode = 'markers',
    marker = list(size = 12)
  ) %>%
  layout(margin=list(l = 100, r = 20, b = 10, t = 10)) %>%
  layout(yaxis = list(tickangle=-35,tickfont=list(size=12))) %>%
  layout(xaxis = list(tickfont=list(size=12)))
}
```

### Pairwise mean F~ST~ by coverage

```{r}
if("popoolation" %in% fst.calc){
 cov.perpair.table.allpools_popoolation %>%
  plot_ly(
    x = ~MeanFST, 
    y = ~pair, 
    color = ~NumSNPs,
    frame = ~MinCoverage, 
    text = ~NumContigs, 
    hoverinfo = ~pair,
    type = 'scatter',
    mode = 'markers',
    marker = list(size = 12)
  ) %>%
  layout(margin=list(l = 100, r = 20, b = 10, t = 10)) %>%
  layout(yaxis = list(tickangle=-35,tickfont=list(size=12))) %>%
  layout(xaxis = list(tickfont=list(size=12)))
}

if("poolfstat" %in% fst.calc){
 cov.perpair.table.allpools_poolfstat %>%
  plot_ly(
    x = ~MeanFST, 
    y = ~pair, 
    color = ~NumSNPs,
    frame = ~MinCoverage, 
    text = ~NumContigs, 
    hoverinfo = ~pair,
    type = 'scatter',
    mode = 'markers',
    marker = list(size = 12)
  ) %>%
  layout(margin=list(l = 100, r = 20, b = 10, t = 10)) %>%
  layout(yaxis = list(tickangle=-35,tickfont=list(size=12))) %>%
  layout(xaxis = list(tickfont=list(size=12)))
}
```

### Locus-by-locus F~ST~

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
if("popoolation" %in% fst.calc){
postpop.master.wide_pp %>%
  plot_ly(
    x = ~.fst, 
    y = ~pair, 
    color = ~popA,
    frame = ~MinCoverage, 
    #text = ~pair, 
    hoverinfo = ~.fst,
    type = 'box'
    #mode = 'markers'
  ) %>%
  layout(margin=list(l = 200, r = 20, b = 80, t = 10)) %>%
  layout(yaxis = list(tickangle=-35,tickfont=list(size=18))) %>%
  layout(xaxis = list(tickfont=list(size=18)))
}

if("poolfstat" %in% fst.calc){
postpop.master.wide_pf %>%
  plot_ly(
    x = ~.fst, 
    y = ~pair, 
    color = ~popA,
    frame = ~MinCoverage, 
    #text = ~pair, 
    hoverinfo = ~.fst,
    type = 'box'
    #mode = 'markers'
  ) %>%
  layout(margin=list(l = 200, r = 20, b = 80, t = 10)) %>%
  layout(yaxis = list(tickangle=-35,tickfont=list(size=18))) %>%
  layout(xaxis = list(tickfont=list(size=18)))
}
```

### FST heatmap parameters
Choose a coverage cutoff and whether to only include sites called in all pools for heatmap generation.
```{r FSTHeatmaps}
#pick a heatmap coverage based on summary plots above
heatmap_cov <- 40

#include only SNPs called in all pools?
all_pools <- FALSE

if("popoolation" %in% fst.calc){
  if (all_pools){ postpop <- postpop.master.long.allpools_popoolation
  } else{ postpop <- postpop.master.long_popoolation }
  hm_list_out <- poolHeatmaps(heatmap_cov=heatmap_cov, postpop=postpop, fst.calc = 'popoolation')
  fst <- as.matrix(hm_list_out$fst)
  chisq <- as.matrix(hm_list_out$chisq)
  plot_ly(z = as.matrix(fst), colors = colorRamp(c("yellow", "red")), x = colnames(fst), y=rownames(fst), type = "heatmap",
        colorbar = list(title = "FST")) %>% layout(margin=list(l = 100, r = 20, b = 80, t = 10)) %>% layout(yaxis = list(tickangle=0,tickfont=list(size=18))) %>%  layout(xaxis = list(tickfont=list(size=18))) 
  plot_ly(z = as.matrix(chisq), colors = colorRamp(c("yellow", "red")), x = colnames(chisq), y=rownames(chisq), type = "heatmap",
        colorbar = list(title = "Chi-Squared")) %>% layout(margin=list(l = 100, r = 20, b = 80, t = 10)) %>% layout(yaxis = list(tickangle=0,tickfont=list(size=18))) %>%  layout(xaxis = list(tickfont=list(size=18)))
  #hc.rows <- hclust(dist(fst))
  #hc.cols <- hclust(dist(t(fst)))
  #heatmap(fst)
}

if("poolfstat" %in% fst.calc){
  if (all_pools){ postpop <- postpop.master.long.allpools_poolfstat
  } else{ postpop <- postpop.master.long_poolfstat }
  hm_list_out <- poolHeatmaps(heatmap_cov=heatmap_cov, postpop=postpop, fst.calc = 'poolfstat')
  fst <- as.matrix(hm_list_out$fst)
  plot_ly(z = as.matrix(fst), colors = colorRamp(c("yellow", "red")), x = colnames(fst), y=rownames(fst), type = "heatmap",
        colorbar = list(title = "FST")) %>% layout(margin=list(l = 100, r = 20, b = 80, t = 10)) %>% layout(yaxis = list(tickangle=0,tickfont=list(size=18))) %>%  layout(xaxis = list(tickfont=list(size=18)))
  #hc.rows <- hclust(dist(fst))
  #hc.cols <- hclust(dist(t(fst)))
  #heatmap(fst)
}

```
### Map setup **NOT STABLE**
```{r}

#vectors for spatial data
pop <- POPS
name <- c("Kure Atoll", "Laysan Isalnd", "Lisianski Island", "Maro Reef", "Maui Island", "Midway Atoll", "Nihoa Isalnd", "Oahu (orange)", "Pearl and Hermes Atoll", "Oahu (red)")
lat <- c(28.3925, 25.7679, 26.0662, 25.4150, 20.7984, 28.2072, 23.0605, 21.4399, 27.8333, 21.4379)
long <- c(-178.2936, -171.7322, -173.9665, -170.5900, -156.3319, -177.3735, -161.9218, -158.0001, -175.8333, -158.0001)

spatdat <- data.frame(pop, name, lats, longs)

colors_for_map <- c("yellow","red")
color_resolution <- 500

fst.named <- fst
dimnames(fst.named) <- list(spatdat$name,spatdat$name)

fst.stand <- (fst-min(fst, na.rm = T))/(max(fst, na.rm = T)-min(fst, na.rm = T))
dimnames(fst.stand) <- list(spatdat$name,spatdat$name)
palette <- colorRampPalette(colors_for_map)
fst.stand <-as.matrix(fst.stand)

fst.cols <- matrix(palette(color_resolution)[as.numeric(cut(as.matrix(fst.stand), breaks = color_resolution))], nrow = length(POPS), ncol = length(POPS))
dimnames(fst.cols) <- list(spatdat$name,spatdat$name)

all1 <- as.data.frame(cbind(t(combn(spatdat$long, 2)), t(combn(spatdat$lat, 2))))
all_pairs <- cbind(all1, as.matrix(t(combn(as.character(spatdat$name), 2))))
colnames(all_pairs) <- c("long1","long2","lat1","lat2", "pop1", "pop2")

addfst <- na.omit(as.data.frame(cbind(rep(rownames(fst.named), ncol(fst.named)), rep(colnames(fst.named), each=nrow(fst.named)), c(as.matrix(fst.named)))))
colnames(addfst) <- c("pop1", "pop2", "fst")
addfst$fst <- as.numeric(as.character(addfst$fst))
all_pairs2 <- left_join(all_pairs, addfst)

addcols <- na.omit(as.data.frame(cbind(rep(rownames(fst.cols), ncol(fst.cols)), rep(colnames(fst.cols), each=nrow(fst.cols)), c(fst.cols))))
colnames(addcols) <- c("pop1", "pop2", "col")
all_pairs3 <- left_join(all_pairs2, addcols)

all_pairs <- all_pairs3
rm(addfst, addcols, all_pairs2, all_pairs3)
```

###Spatial visualization **NOT STABLE**
```{r}
latrange <- max(all_pairs$lat1)-min(all_pairs$lat1)
longrange <- max(all_pairs$long1)-min(all_pairs$long1)
latasp <- c(min(all_pairs$lat1)-((longrange/latrange)*(latrange/2)),max(all_pairs$lat1)+((longrange/latrange)*(latrange/2)))
longasp <- c(min(all_pairs$long1)-((latrange/longrange)*(longrange/2)),max(all_pairs$long1)+((latrange/longrange)*(longrange/2)))
  
worldmap <- borders("world", colour="black", fill="gray40", xlim = longasp, ylim = latasp) # create a layer of borders
p1 <-  ggplot() + worldmap + 
 geom_curve(data=all_pairs, aes(x = long1, y = lat1, xend = long2, yend = lat2, col = fst, size = -fst), curvature = .4) +
 geom_point(data=spatdat, aes(x = long, y = lat), col = "#970027") + 
  geom_text_repel(data=spatdat, aes(x = long, y = lat, label = name), size = 10) + 
  scale_color_gradient2(low = "red", mid = "yellow", high = "white", midpoint = .1) +
  scale_size_continuous(range = c(2,.00000001)) +
  theme(panel.background = element_rect(fill=alpha("steelblue",0.2)),
        axis.line = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank()
  )

p1
```

